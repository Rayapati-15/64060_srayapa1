---
title: "Assignment 3 FML"
author: "Sudarshan.Rayapati"
date: "2023-10-15"
output:
  html_document: default
  pdf_document: default
---

``````{r setup, include=TRUE,  results='hide'}
knitr::opts_chunk$set(echo = TRUE)
```


***
# Summary
# 1:-According to the given dataset, if an accident has just been reported and no further information is available, there is a 50.88% chance that the injury has taken place, because data suggests that previously out of 42,183 cases, 21,462 cases have reported "injury=yes".

# 2.1: The exact Bayes conditional probabilities of an injury (INJURY = Yes) for the six possible combinations of the predictons are:

Predictor combination	Probability
WEATHER_R = 1 and TRAF_CON_R = 1	0.6666667
WEATHER_R = 2 and TRAF_CON_R = 0	0.1818182
WEATHER_R = 1 and TRAF_CON_R = 1	0.0000000
WEATHER_R = 2 and TRAF_CON_R = 1	0.0000000
WEATHER_R = 1 and TRAF_CON_R = 2	0.0000000
WEATHER_R = 2 and TRAF_CON_R = 2	1.0000000
2.2: The Classification of the 24 accidents using their probabilities and a cutoff of 0.5 quantitatively are:

[0.6666667 0.1818182 0.0000000 0.0000000 0.6666667 0.1818182 0.1818182 0.6666667 0.1818182 0.1818182 0.1818182 0.0000000 0.6666667 0.6666667 0.6666667 0.6666667 0.1818182 0.1818182 0.1818182 0.1818182 0.6666667 0.6666667 1.0000000 0.1818182]

qualitatively are:

["yes" "no" "no" "no" "yes" "no" "no" "yes" "no" "no" "no" "no" "yes" "yes" "yes" "yes" "no" "no" "no" "no" "yes" "yes" "yes" "no"]

# 2.3: The Computation of the naive Bayes conditional probability of an injury given WEATHER_R = 1 and TRAF_CON_R = 1 manually the output is "0".

# 2.4: Now, after applying the naïve Bayes classifier to the 24 records and two predictors, checking the model output to get probabilities and classifications for all 24 records, it was identified that the result of  classification and ranks were not equal as the Exact Bayes caluclation.

# 3.1: When we applied the naive Bayes classifier to the full training set with the key predictors and used "INJURY" as the response, the results shows us confusion matrix and statistics. The accuracy of the model turned out to be 53.7%. This tells us that the model predicts whether an accident causes injury or not.

Confusion Matrix and Statistics

          Reference
Prediction   no  yes
       no  3444 4866
       yes 2947 5617
                                          
               Accuracy : 0.537  

# 3.2: the overall error of the validation set is "46.3".

****
# Problem Statement

The file accidentsFull.csv contains information on 42,183 actual automobile accidents in 2001 in the United States that involved one of three levels of injury: NO INJURY, INJURY, or FATALITY. For each accident, additional information is recorded, such as day of week, weather conditions, and road type.
A firm might be interested in developing a system for quickly classifying the severity of an accident based on initial reports and associated data in the system (some of which rely on GPS-assisted reporting).

Our aim is to predict whether an accident just reported will involve an injury (MAX_SEV_IR = 1 or 2) or will not (MAX_SEV_IR = 0). For this purpose, create a dummy variable called INJURY that takes the value “yes” if MAX_SEV_IR = 1 or 2, and otherwise “no.”

******
  
## Data Input and Cleaning
Loading the required libraries and reading the input file
```{r}
library(e1071)
library(caret)
library(ggplot2)
```
***
# Q1. Using the information in this dataset, if an accident has just been reported and no further information is available, what should the prediction be? (INJURY = Yes or No?) Why?
```{r}
accidents_24 <- read.csv("/Users/sudarshan/Desktop/FML/dataset/accidentsFull.csv")
accidents_24$INJURY = ifelse(accidents_24$MAX_SEV_IR>0,"yes","no")
injury_table <- table(accidents_24$INJURY)
injury_table
head(accidents_24)
probability_injury <- (injury_table["yes"] / sum(injury_table))*100
probability_injury

```

```{r}
#Converting variables into factor
for (i in c(1:dim(accidents_24)[2])){
  accidents_24[,i] <- as.factor(accidents_24[,i])
}
head(accidents_24,n=24)
```
***
# Q2. Select the first 24 records in the dataset and look only at the response (INJURY) and the two predictors WEATHER_R and TRAF_CON_R. Create a pivot table that examines INJURY as a function of the two predictors for these 12 records. Use all three variables in the pivot table as rows/columns.
  
```{r}
accidents_24_Df <- accidents_24[1:24,c("INJURY","WEATHER_R","TRAF_CON_R")]
head(accidents_24_Df)
```

```{r}
Pt1 <- ftable(accidents_24_Df)
Pt2 <- ftable(accidents_24_Df[,-1]) # print table only for conditions
Pt1
Pt2
```

# 2.1:- Compute the exact Bayes conditional probabilities of an injury (INJURY = Yes) given the six possible combinations of the predictors.
```{r}
#Injury = yes
p1 = Pt1[3,1] / Pt2[1,1] # Injury, Weather=1 and Traf=0
p2 = Pt1[4,1] / Pt2[2,1] # Injury, Weather=2, Traf=0
p3 = Pt1[3,2] / Pt2[1,2] # Injury, W=1, T=1
p4 = Pt1[4,2] / Pt2[2,2] # I, W=2,T=1
p5 = Pt1[3,3] / Pt2[1,3] # I, W=1,T=2
p6 = Pt1[4,3]/ Pt2[2,3] #I,W=2,T=2

# Injury = no
n1 = Pt1[1,1] / Pt2[1,1] # Weather=1 and Traf=0
n2 = Pt1[2,1] / Pt2[2,1] # Weather=2, Traf=0
n3 = Pt1[1,2] / Pt2[1,2] # W=1, T=1
n4 = Pt1[2,2] / Pt2[2,2] # W=2,T=1
n5 = Pt1[1,3] / Pt2[1,3] # W=1,T=2
n6 = Pt1[2,3] / Pt2[2,3] # W=2,T=2
print(c(p1,p2,p3,p4,p5,p6))
print(c(n1,n2,n3,n4,n5,n6))
```

# 2.2:-Classify the 24 accidents using these probabilities and a cutoff of 0.5.
```{r}
prob.inj <- rep(0,24)

for (i in 1:24) {
  print(c(accidents_24_Df$WEATHER_R[i],accidents_24_Df$TRAF_CON_R[i]))
    if (accidents_24_Df$WEATHER_R[i] == "1") {
      if (accidents_24_Df$TRAF_CON_R[i]=="0"){
        prob.inj[i] = p1
      }
      else if (accidents_24_Df$TRAF_CON_R[i]=="1") {
        prob.inj[i] = p3
      }
      else if (accidents_24_Df$TRAF_CON_R[i]=="2") {
        prob.inj[i] = p5
      }
    }
    else {
      if (accidents_24_Df$TRAF_CON_R[i]=="0"){
        prob.inj[i] = p2
      }
      else if (accidents_24_Df$TRAF_CON_R[i]=="1") {
        prob.inj[i] = p4
      }
      else if (accidents_24_Df$TRAF_CON_R[i]=="2") {
        prob.inj[i] = p6
      }
    }
  }
  

accidents_24_Df$prob.inj <- prob.inj
accidents_24_Df$prob.inj
accidents_24_Df$pred.prob <- ifelse(accidents_24_Df$prob.inj>0.5, "yes", "no")
accidents_24_Df$pred.prob

```

# 2.3Compute manually the naive Bayes conditional probability of an injury given WEATHER_R = 1 and TRAF_CON_R = 1.

Answer:- Probability(Injury=Yes/WEATHER_R=1,TRAF_CON_R=1)

= [ Probability(W=1/Injury=Yes) * Probability(TRAF_CON_R=1/Injury=Yes) * Probability(Injury=Yes) ]
                                                /
[ Probability(W=1/Injury=Yes) * Probability(TRAF_CON_R=1/Injury=Yes) * Probability(Injury=Yes) + Probability(WEATHER_R=1/Injury=No) * Probability(TRAF_CON_R=1/Injury=No) * Probability(Injury=No) ]

= [ 6/9 * 0/9 * 9/24 ] / [ 6/9 * 0/9 * 9/24 + 5/15 * 2/15 * 15/24 ] 
=  The result will be "0" Because the numerator is zero.


# 2.4:- Run a naive Bayes classifier on the 24 records and two predictors. Check the model output to obtain probabilities and classifications for all 24 records. Compare this to the exact Bayes classification. Are the resulting classifications equivalent? Is the ranking (= ordering) of observations equivalent?
```{r}
nb <- naiveBayes(INJURY ~ TRAF_CON_R + WEATHER_R, 
                 data = accidents_24_Df)

nbt <- predict(nb, newdata = accidents_24_Df,type = "raw")
accidents_24_Df$nbpred.prob <- nbt[,2] # Transfer the "Yes" nb prediction
accidents_24_Df$nbpred.prob
```
  
```{r}

library(klaR) 
#Loading the klaR package 

# Creating a variable named formula 
formula <- INJURY ~ TRAF_CON_R + WEATHER_R
# Training the Naive Bayes model with Laplace

accidents_24_Df$INJURY <- as.factor(accidents_24_Df$INJURY)
nb2 <- NaiveBayes(formula,data = accidents_24_Df, laplace = 1)

# Making predictions with the model
 predict(nb2, newdata = accidents_24_Df[, c("INJURY", "WEATHER_R", "TRAF_CON_R")])

predict(nb2, newdata = accidents_24_Df[, c("INJURY", "WEATHER_R", "TRAF_CON_R")], type = "raw")
#predictions
#raw_probabilities

```

```{r}
# Comparing Both naive Bayes model and exact Bayes classification
classification_match <- all(accidents_24_Df$nbpred.prob == accidents_24_Df$prob.inj)
probability_match <- all.equal(accidents_24_Df$nbpred.prob, accidents_24_Df$prob.inj)

# Checking if classifications and rankings are equal
if (classification_match && is.na(probability_match)) {
  cat("The resulting classifications and rankings are equal.\n")
} else {
  cat("The resulting classifications and rankings are not equal.\n")
}

```
***
Q3, Let us now return to the entire dataset. Partition the data into training (60%) and validation (40%). 
3.1, Run a naive Bayes classifier on the complete training set with the relevant predictors(and INJURY as the response). Note that all predictors are categorical. Show the confusion matrix.

```{r}
set.seed(1)
train.index <- sample(c(1:dim(accidents_24)[1]), dim(accidents_24)[1]*0.6)  
train.df <- accidents_24[train.index,]
valid.df <- accidents_24[-train.index,]
#Identifying a variable to use 
vars <- c("INJURY", "HOUR_I_R",  "ALIGN_I" ,"WRK_ZONE",  "WKDY_I_R",
          "INT_HWY",  "LGTCON_I_R", "PROFIL_I_R", "SPD_LIM", "SUR_COND",
          "TRAF_CON_R",   "TRAF_WAY",   "WEATHER_R")

nbTotal <- naiveBayes(INJURY~.,data = train.df[,vars])
nbTotal
3
#Creating the confusion matrix using the train.df, the prediction and the classes
confusionMatrix(train.df$INJURY, predict(nbTotal, train.df[, vars]), positive = "yes")
```

# 3.2, What is the overall error of the validation set?
```{r}
confusionMatrix(valid.df$INJURY, predict(nbTotal, valid.df[, vars]), positive = "yes")
```

```{r}
#Calculating the overall error

ver=1-0.5331
verp=ver*100
paste("Overall Error: ",verp)
```


***
###CONCLUSION 

Using two predictors both times, the Naive Bayes classifier was applied to first predict injury outcomes in a data set of 24 records and subsequently to the whole data set.

Using the exact Bayes classifier for the first 24 records, we identified that the most risky combination for drivers is WEATHER_CON=2,TRAF_CON=0 since the injury is max at "1" in this case.

The model has a validation error of 46.3% and a training set accuracy of 53.7%, showing a modest level of prediction. However, it makes the assumption that the prediction variables are independent, which may not always be the case in real-world situations and might result in errors.But for classification and ranking, we may use the Naive Bayes classifier.

While Naive Bayes is a simple and effective algorithm for injury outcome prediction, it's crucial to remember its limitations.

